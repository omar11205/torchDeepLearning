{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Element-wise operations in pytorch: https://deeplizard.com/learn/video/QscEWm0QTRY",
   "id": "468cdbf36716c4a0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T20:35:48.756616Z",
     "start_time": "2024-05-14T20:35:46.124117Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:30:29.232842Z",
     "start_time": "2024-05-01T03:30:29.230211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# computational dynamic graph is a ds that helps to track changes in a tensor using graphs ds. The next code sets up computational tracking on a tensor\n",
    "x = torch.tensor(2.0, requires_grad=True)"
   ],
   "id": "d55e197a08ac6edb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:30:29.238364Z",
     "start_time": "2024-05-01T03:30:29.232842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining a tensorial function \n",
    "y = 2*x**4 + x**3 + 3*x**2 + 5*x + 1\n",
    "print(y)"
   ],
   "id": "4900d1b1486f139a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:16:01.897012Z",
     "start_time": "2024-05-01T04:16:01.893541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# numerical differentiation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x\n",
    "\n",
    "def numerical_lim(f, x, h):\n",
    "    return (f(x+h)-f(x))/h\n",
    "\n",
    "h = 0.1\n",
    "for i in range(7):\n",
    "    print(f'h={h: 6f}, numerical limit = {numerical_lim(f, 1, h):.6f}')\n",
    "    h *= 0.1"
   ],
   "id": "3fd805e804dfdc06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h= 0.100000, numerical limit = 2.300000\n",
      "h= 0.010000, numerical limit = 2.030000\n",
      "h= 0.001000, numerical limit = 2.003000\n",
      "h= 0.000100, numerical limit = 2.000300\n",
      "h= 0.000010, numerical limit = 2.000030\n",
      "h= 0.000001, numerical limit = 2.000003\n",
      "h= 0.000000, numerical limit = 2.000000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:26.918450Z",
     "start_time": "2024-05-07T22:18:26.914616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(4.0, requires_grad=True)\n",
    "print(x.grad) # the default value is None"
   ],
   "id": "127bc8c957ca1342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:29.622837Z",
     "start_time": "2024-05-07T22:18:29.607798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = torch.dot(x,x) # f(x_vector) = x . x = (||x||)^2 = (sqrt(x1^2 + ... xn^2))^2 = x1^2 + ... xn^2\n",
    "print(y)"
   ],
   "id": "3bd62e7d97647e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:31.271519Z",
     "start_time": "2024-05-07T22:18:31.268398Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "750b443dd39f3657",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:33.509419Z",
     "start_time": "2024-05-07T22:18:33.505522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(x)\n",
    "print(x.grad)"
   ],
   "id": "6912e60163cf062e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:40.175655Z",
     "start_time": "2024-05-07T22:18:40.171537Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad == 2*x # check if 2*x is the general vector function solution of the operation grad(x_vector)",
   "id": "4dd896cc515d7d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:45.202546Z",
     "start_time": "2024-05-07T22:18:45.198539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another example \n",
    "# f(x_vector) = x1 + x2 + ... + xn\n",
    "# IMPORTANT!!! torch accumulates the gradient, to reset the gradient to zeros\n",
    "x.grad.zero_()"
   ],
   "id": "689ff0440f7e0a7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:18:52.097792Z",
     "start_time": "2024-05-07T22:18:52.094277Z"
    }
   },
   "cell_type": "code",
   "source": "print(x.grad)",
   "id": "3a2f077df40c3656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:27:25.705220Z",
     "start_time": "2024-05-02T03:27:25.701278Z"
    }
   },
   "cell_type": "code",
   "source": "print(x)",
   "id": "c281fc39db0a4c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:19:04.558187Z",
     "start_time": "2024-05-07T22:19:04.553249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the derivative of a variable with respect to itself: dx/dx == 1\n",
    "y = x.sum() # f(x_vector) = x1 + x2 + ... + xn\n",
    "print(y)\n",
    "y.backward()\n",
    "print(x.grad)"
   ],
   "id": "33a46f6485b45820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6., grad_fn=<SumBackward0>)\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example 3. Backward for non-scalar variables. For non-scalar variables torch calculates the gradient as $\\mathbf{J}(\\vec{y})^\\intercal \\cdot \\vec{v}$",
   "id": "29bbd0f45e9d2895"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\vec{x} = \\begin{bmatrix} x_{1}\\\\ x_{2}\\\\ x_{3} \\end{bmatrix} \\rightarrow \\vec{y} = \\begin{bmatrix} y_{1} = x_{1}^{2}\\\\ y_{2} = x_{2}^{2}\\\\ y_{3} = x_{3}^{2} \\end{bmatrix} \\hspace{1cm} \\left ( f:\\mathbb{R}^{3}\\rightarrow \\mathbb{R}^{3} \\right )\n",
    "$$"
   ],
   "id": "cfd811d244e5a240"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With non-scalar values the analysis must have in count the way that torch generally calculates the gradient. Torch calculates the gradients in base to the Jacobian (J) of y and an auxiliar vector v. In this particular case J(y) is by definition:",
   "id": "5c2ad3440b563ba3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\mathbf {J}(\\vec{y}) ={\\begin{bmatrix}{\\dfrac {\\partial \\vec{y} }{\\partial x_{1}}} & \\dfrac {\\partial \\vec{y} }{\\partial x_{2}} & {\\dfrac {\\partial \\vec{y} }{\\partial x_{3}}}\\end{bmatrix}} = {\\begin{bmatrix}\\nabla ^{\\mathrm {T} }\\vec{y}_{1}\\\\ \\nabla ^{\\mathrm {T} }\\vec{y}_{2} \\\\ \\nabla ^{\\mathrm {T} }\\vec{y}_{3}\\end{bmatrix}}\n",
    "$$"
   ],
   "id": "2a19d259a9d5ebed"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\mathbf{J}(\\vec{y}) =\n",
    "\\begin{bmatrix}\n",
    "  \\frac{\\partial y_1}{\\partial x_1} & \n",
    "    \\frac{\\partial y_1}{\\partial x_2} & \n",
    "    \\frac{\\partial y_1}{\\partial x_3} \\\\ \n",
    "  \\frac{\\partial y_2}{\\partial x_1} & \n",
    "    \\frac{\\partial y_2}{\\partial x_2} & \n",
    "    \\frac{\\partial y_2}{\\partial x_3} \\\\\n",
    "  \\frac{\\partial y_3}{\\partial x_1} & \n",
    "    \\frac{\\partial y_3}{\\partial x_2} & \n",
    "    \\frac{\\partial y_3}{\\partial x_3}\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "id": "89f8f4fce9ab28c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For non-scalar values the gradient is calculated in terms of the product of the transpose of the Jacobian of the final vector (y) and an auxiliar vector (v), in this case v = identity vector",
   "id": "41a865cacc68253e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\mathbf{J}(\\vec{y})^\\intercal \\cdot \\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "  \\frac{\\partial y_1}{\\partial x_1} & \n",
    "    \\frac{\\partial y_2}{\\partial x_1} & \n",
    "    \\frac{\\partial y_3}{\\partial x_1} \\\\ \n",
    "  \\frac{\\partial y_1}{\\partial x_2} & \n",
    "    \\frac{\\partial y_2}{\\partial x_2} & \n",
    "    \\frac{\\partial y_3}{\\partial x_2} \\\\\n",
    "  \\frac{\\partial y_1}{\\partial x_3} & \n",
    "    \\frac{\\partial y_2}{\\partial x_3} & \n",
    "    \\frac{\\partial y_3}{\\partial x_3}\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$\n"
   ],
   "id": "d3aef7aa55d55cf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\mathbf{J}(\\vec{y})^\\intercal \\cdot \\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "  \\frac{\\partial (x_{1}^{2})}{\\partial x_1} & \n",
    "    \\frac{\\partial (x_{2}^{2})}{\\partial x_1} & \n",
    "    \\frac{\\partial (x_{3}^{2})}{\\partial x_1} \\\\ \n",
    "  \\frac{\\partial (x_{1}^{2})}{\\partial x_2} & \n",
    "    \\frac{\\partial (x_{2}^{2})}{\\partial x_2} & \n",
    "    \\frac{\\partial (x_{3}^{2})}{\\partial x_2} \\\\\n",
    "  \\frac{\\partial (x_{1}^{2})}{\\partial x_3} & \n",
    "    \\frac{\\partial (x_{2}^{2})}{\\partial x_3} & \n",
    "    \\frac{\\partial (x_{3}^{2})}{\\partial x_3}\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "id": "66c276c55d8bb93a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "   2x_{1} & \n",
    "    0 & \n",
    "    0 \\\\ \n",
    "  0 & \n",
    "    2x_{2} & \n",
    "    0 \\\\\n",
    "  0 & \n",
    "    0 & \n",
    "    2x_{3}\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} \n",
    "2x_{1} \\\\\n",
    "2x_{2} \\\\\n",
    "2x_{3}\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "id": "853745f359109da5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:14:10.147052Z",
     "start_time": "2024-05-07T22:14:10.118852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# backward for non-scalar variables\n",
    "x = torch.arange(3.0, requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad)"
   ],
   "id": "adb01addf27299cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:14:13.554214Z",
     "start_time": "2024-05-07T22:14:13.550740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in torch to make y_vector = [(x_1)^2, (x_2)^2, (x_3)^2] (remembering that x_1, x_2, x_3 = the components of x_vector) we can use element-wise operation on x\n",
    "y = x * x "
   ],
   "id": "ed87bcc486e29a69",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T22:14:35.654510Z",
     "start_time": "2024-05-07T22:14:35.030697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y.backward(torch.ones_like(x)) \n",
    "print(x.grad)\n",
    "x.grad == 2*x"
   ],
   "id": "823d41ceb9082cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Example 4. Backward for non-scalar variables.\n",
    "\n",
    "$$ Q = 3a^{3} - b^{2} $$\n",
    "\n",
    "$$\n",
    "\\vec{a} = \\begin{bmatrix}\n",
    "a_{1}\\\\ \n",
    "a_{2}\\\\ \n",
    "\n",
    "\\end{bmatrix}, \\vec{b} = \\begin{bmatrix}\n",
    "b_{1}\\\\ \n",
    "b_{2}\\\\ \n",
    "\n",
    "\\end{bmatrix} \\rightarrow \\vec{Q} = \\begin{bmatrix}\n",
    "Q_{1}\\\\ \n",
    "Q_{2}\\\\ \n",
    "\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "3a_{1}^{3}-3b_{1}^{2}\\\\ \n",
    "3a_{2}^{3}-3b_{2}^{2}\\\\ \n",
    "\n",
    "\\end{bmatrix} \\hspace{1cm} \\left ( f:\\mathbb{R}^{2}\\rightarrow \\mathbb{R}^{2} \\right )\n",
    "$$\n",
    " "
   ],
   "id": "d37f1d9daccbe33b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The jacobian of $\\vec{Q}$ is:\n",
    "\n",
    "$$\n",
    "\\mathbf{J}(\\vec{Q}) =\n",
    "\\begin{bmatrix}\n",
    "  \\frac{\\partial Q_1}{\\partial a_1} & \n",
    "    \\frac{\\partial Q_1}{\\partial b_1} & \n",
    "    \\frac{\\partial Q_1}{\\partial a_2} &\n",
    "    \\frac{\\partial Q_1}{\\partial b_2} \\\\\n",
    "  \\frac{\\partial Q_2}{\\partial a_1} & \n",
    "    \\frac{\\partial Q_2}{\\partial b_1} & \n",
    "    \\frac{\\partial Q_2}{\\partial a_2} &\n",
    "    \\frac{\\partial Q_2}{\\partial b_2} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{J}(\\vec{Q}) =\n",
    "\\begin{bmatrix}\n",
    "  9a_{1}^{2} & \n",
    "    -2b_{1} & \n",
    "    0 &\n",
    "    0 \\\\\n",
    "  0 & \n",
    "    0 & \n",
    "    9a_{2}^{2}  &\n",
    "    -2b_{2} \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "id": "16f1da6a949074d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The torch automatic backward calculation with the necesary $\\vec{v}$ then will be\n",
    "\n",
    "$$\n",
    "\\mathbf{J}^T(\\vec{Q})\\cdot \\vec{v} =\n",
    "\\begin{bmatrix}\n",
    "  9a_{1}^{2} & \n",
    "    0 \\\\\n",
    "  -2b_{1} & \n",
    "    0 \\\\\n",
    "  0 & \n",
    "    9a_{2}^{2} \\\\\n",
    "  0 & \n",
    "    -2b_{2} \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "1 \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "9a_{1}^{2} \\\\\n",
    "-2b_{1} \\\\\n",
    "9a_{2}^{2} \\\\\n",
    "-2b_{2}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ],
   "id": "3be2a470db7a96da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T20:47:27.236267Z",
     "start_time": "2024-05-14T20:47:27.231479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "v = torch.tensor([1, 1])\n",
    "\n",
    "Q = 3*a**3 - b**2\n",
    "Q.backward(gradient=v)\n",
    "print(a.grad, b.grad)\n",
    "\n",
    "print(a.grad == 9*a**2)\n",
    "print(b.grad == -2*b)"
   ],
   "id": "83623ea3208bc474",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.]) tensor([-12.,  -8.])\n",
      "tensor([True, True])\n",
      "tensor([True, True])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5745de12a61baf5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "57b9c15afe5965cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ed81af12bb9fe248"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
