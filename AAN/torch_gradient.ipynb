{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-02T03:12:29.790852Z",
     "start_time": "2024-05-02T03:12:26.956191Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:30:29.232842Z",
     "start_time": "2024-05-01T03:30:29.230211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# computational dynamic graph is a ds that helps tracking changes in a tensor using graphs ds. The next code sets up computational tracking on a tensor\n",
    "x = torch.tensor(2.0, requires_grad=True)"
   ],
   "id": "d55e197a08ac6edb",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T03:30:29.238364Z",
     "start_time": "2024-05-01T03:30:29.232842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# defining a tensorial function \n",
    "y = 2*x**4 + x**3 + 3*x**2 + 5*x + 1\n",
    "print(y)"
   ],
   "id": "4900d1b1486f139a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T04:16:01.897012Z",
     "start_time": "2024-05-01T04:16:01.893541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# numerical differentiation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x\n",
    "\n",
    "def numerical_lim(f, x, h):\n",
    "    return (f(x+h)-f(x))/h\n",
    "\n",
    "h = 0.1\n",
    "for i in range(7):\n",
    "    print(f'h={h: 6f}, numerical limit = {numerical_lim(f, 1, h):.6f}')\n",
    "    h *= 0.1"
   ],
   "id": "3fd805e804dfdc06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h= 0.100000, numerical limit = 2.300000\n",
      "h= 0.010000, numerical limit = 2.030000\n",
      "h= 0.001000, numerical limit = 2.003000\n",
      "h= 0.000100, numerical limit = 2.000300\n",
      "h= 0.000010, numerical limit = 2.000030\n",
      "h= 0.000001, numerical limit = 2.000003\n",
      "h= 0.000000, numerical limit = 2.000000\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:12:29.803485Z",
     "start_time": "2024-05-02T03:12:29.791858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.arange(4.0, requires_grad=True)\n",
    "print(x.grad) # the default value is None"
   ],
   "id": "127bc8c957ca1342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:13:41.365396Z",
     "start_time": "2024-05-02T03:13:41.346441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y = torch.dot(x,x) # f(x_vector) = x . x = (||x||)^2 = (sqrt(x1^2 + ... xn^2))^2 = x1^2 + ... xn^2\n",
    "print(y)"
   ],
   "id": "3bd62e7d97647e4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14., grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:21:47.964840Z",
     "start_time": "2024-05-02T03:21:47.912538Z"
    }
   },
   "cell_type": "code",
   "source": "y.backward()",
   "id": "750b443dd39f3657",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:22:17.656912Z",
     "start_time": "2024-05-02T03:22:17.653462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(x)\n",
    "print(x.grad)"
   ],
   "id": "6912e60163cf062e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], requires_grad=True)\n",
      "tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:22:49.424480Z",
     "start_time": "2024-05-02T03:22:49.418743Z"
    }
   },
   "cell_type": "code",
   "source": "x.grad == 2*x # check if 2*x is the general vector function solution of the operation grad(x_vector)",
   "id": "4dd896cc515d7d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:26:53.035234Z",
     "start_time": "2024-05-02T03:26:53.031344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# another example \n",
    "# f(x_vector) = x1 + x2 + ... + xn\n",
    "# IMPORTANT!!! torch accumulates the gradient, to reset the gradient to zeros\n",
    "x.grad.zero_()"
   ],
   "id": "689ff0440f7e0a7c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:27:10.921533Z",
     "start_time": "2024-05-02T03:27:10.918678Z"
    }
   },
   "cell_type": "code",
   "source": "print(x.grad)",
   "id": "3a2f077df40c3656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0.])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:27:25.705220Z",
     "start_time": "2024-05-02T03:27:25.701278Z"
    }
   },
   "cell_type": "code",
   "source": "print(x)",
   "id": "c281fc39db0a4c41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T03:29:48.058333Z",
     "start_time": "2024-05-02T03:29:48.052268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# the derivative of a variable with respect to itself: dx/dx == 1\n",
    "y = x.sum() # f(x_vector) = x1 + x2 + ... + xn\n",
    "y.backward()\n",
    "print(x.grad)"
   ],
   "id": "33a46f6485b45820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# backward for non-scalar variables",
   "id": "e1eba367671223e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
