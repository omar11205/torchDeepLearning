{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prediction of New York City Taxi Fares\n",
    "In this section we will transform the dataset in order to create new useful datetime and distance features, with this new features we will try to predict with regression the fare amount of the taxi rides taking with the rest of the features less the fare class. In the second part we will try to predict the fare class using embeddings and PyTorch embedding layers for the zipcodes.\n",
    "\n",
    "Description of the dataset\n",
    "\n",
    "Features:\n",
    " \n",
    "- pickup_datetime - timestamp value indicating when the taxi ride started.\n",
    "- pickup_longitude - float for longitude coordinate of where the taxi ride started.\n",
    "- pickup_latitude - float for latitude coordinate of where the taxi ride started.\n",
    "- dropoff_longitude - float for longitude coordinate of where the taxi ride ended.\n",
    "- dropoff_latitude - float for latitude coordinate of where the taxi ride ended.\n",
    "- passenger_count - integer indicating the number of passengers in the taxi ride.\n",
    "\n",
    "Target\n",
    "- fare_amount: float dollar amount of the cost of the taxi ride. This value is only in the training set; this is what you are predicting in the test set and it is required in your submission CSV.\n",
    "\n",
    "### Get the traveled distance with the coordinates\n",
    "\n",
    "A Regression approach that correlates the traveled distance with the fare amount per ride needs a traveled distance calculation with the coordinates provided. For this reason a new feature could be calculated with the Haversine formula that calculates the distance on a sphere between two sets of GPS coordinates. With this, we reduce the complexity of the travel with a straight line. \n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "$${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{split}$"
   ],
   "id": "4ce256f93be403d0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T17:21:45.526152Z",
     "start_time": "2024-08-05T17:21:38.129385Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:21:49.346414Z",
     "start_time": "2024-08-05T17:21:49.325748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(42)\n",
    "# Defining an early stopping class for PyTorch\n",
    "import copy\n",
    "class EarlyStopping:\n",
    "  def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "    self.patience = patience\n",
    "    self.min_delta = min_delta\n",
    "    self.restore_best_weights = restore_best_weights\n",
    "    self.best_model = None\n",
    "    self.best_loss = None\n",
    "    self.patience_counter = 0\n",
    "    self.status = \"\"\n",
    "\n",
    "  def __call__(self, model, val_loss):\n",
    "    if self.best_loss is None:\n",
    "      self.best_loss = val_loss\n",
    "      self.best_model = copy.deepcopy(model.state_dict())\n",
    "    elif self.best_loss - val_loss >= self.min_delta:\n",
    "      self.best_model = copy.deepcopy(model.state_dict())\n",
    "      self.best_loss = val_loss\n",
    "      self.status = f\"Improvement!!!, actual counter {self.patience_counter}\"\n",
    "      self.patience_counter = 0\n",
    "    else:\n",
    "      self.patience_counter += 1\n",
    "      self.status = f\"NO improvement in the last {self.patience_counter} epochs\"\n",
    "      if self.patience_counter >= self.patience:\n",
    "        self.status = f\"Early stopping triggered after {self.patience_counter} epochs.\"\n",
    "        if self.restore_best_weights:\n",
    "          model.load_state_dict(self.best_model)\n",
    "        return True\n",
    "    return False"
   ],
   "id": "cf1a78a3727a15db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:22:11.359918Z",
     "start_time": "2024-08-05T17:22:11.177133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the MPG dataset\n",
    "df = pd.read_csv(\"data/NYCTaxiFares.csv\", na_values=[\"NA\", \"?\"])\n",
    "\n",
    "# check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)"
   ],
   "id": "1a36c0e550f264a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_datetime      0\n",
      "fare_amount          0\n",
      "fare_class           0\n",
      "pickup_longitude     0\n",
      "pickup_latitude      0\n",
      "dropoff_longitude    0\n",
      "dropoff_latitude     0\n",
      "passenger_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:23:07.969085Z",
     "start_time": "2024-08-05T17:23:07.930313Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "350539a6a8c537b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   pickup_datetime    120000 non-null  object \n",
      " 1   fare_amount        120000 non-null  float64\n",
      " 2   fare_class         120000 non-null  int64  \n",
      " 3   pickup_longitude   120000 non-null  float64\n",
      " 4   pickup_latitude    120000 non-null  float64\n",
      " 5   dropoff_longitude  120000 non-null  float64\n",
      " 6   dropoff_latitude   120000 non-null  float64\n",
      " 7   passenger_count    120000 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:23:35.739753Z",
     "start_time": "2024-08-05T17:23:35.723517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# function to calculate the distance of the travel\n",
    "def haversine_distance(df, lat1, lon1, lat2, lon2):\n",
    "    \n",
    "    # average radius of the Earth in (km)\n",
    "    r = 6371\n",
    "    \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2] - df[lat1])\n",
    "    delta_lambda = np.radians(df[lon2] - df[lon1])\n",
    "    \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c)\n",
    "    \n",
    "    return d"
   ],
   "id": "8c0a117119eb6af8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:23:40.012035Z",
     "start_time": "2024-08-05T17:23:39.969421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# append a 'dist_km' new feature in the dataframe\n",
    "df['dist_km'] = haversine_distance(df, 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()\n"
   ],
   "id": "3d207cbabcc4b174",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Time datatypes transformations\n",
    "To work with the special pandas dtype timestamps the to_datetime method can be used."
   ],
   "id": "cea38f6614813d27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:24:32.528350Z",
     "start_time": "2024-08-05T17:24:28.668631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# actual dtypes\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "time_sample = df['pickup_datetime'][0]\n",
    "print(time_sample)\n",
    "type(time_sample)"
   ],
   "id": "45b8c4bf8671f830",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-04-19 08:17:56+00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Correcting pickup_datetime due to daylight savings time (April) There is a 4 hour difference between the value in the dataframe and the real NYC time. Eastern Day Time.",
   "id": "b76a840b247ce3ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:27:12.791481Z",
     "start_time": "2024-08-05T17:27:12.771111Z"
    }
   },
   "cell_type": "code",
   "source": "df['EDTdate'] = df['pickup_datetime'] - pd.Timedelta(hours=4)",
   "id": "ae7f36a02e8631fb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extract new features from the time series",
   "id": "8ae6b42e6e3fdaa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:28:11.888502Z",
     "start_time": "2024-08-05T17:28:11.120619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12, 'am', 'pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ],
   "id": "c970a91820fa9d24",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0 2010-04-19 08:17:56+00:00          6.5           0        -73.992365   \n",
       "1 2010-04-17 15:43:53+00:00          6.9           0        -73.990078   \n",
       "2 2010-04-17 11:23:26+00:00         10.1           1        -73.994149   \n",
       "3 2010-04-11 21:25:03+00:00          8.9           0        -73.990485   \n",
       "4 2010-04-17 02:19:01+00:00         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km                   EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56+00:00     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53+00:00    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26+00:00     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03+00:00    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01+00:00    22     pm     Fri  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56+00:00</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53+00:00</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26+00:00</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03+00:00</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03+00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01+00:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01+00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Managing categorical and continuous values in Pandas\n",
    "Defining arbitrary continuous categories, arbitrary continuous columns and the target feature"
   ],
   "id": "a3b168ca538b778a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:31:00.660017Z",
     "start_time": "2024-08-05T17:31:00.648430Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "2064caece9518c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:35:33.696232Z",
     "start_time": "2024-08-05T17:35:33.683710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'passenger_count', 'dist_km']\n",
    "\n",
    "# target feature for regression task\n",
    "y_col = ['fare_amount']"
   ],
   "id": "9c542c8e062f99e6",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How to know the pandas category dtype",
   "id": "f6f0bb6c31cf5b96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:35:38.634834Z",
     "start_time": "2024-08-05T17:35:38.626366Z"
    }
   },
   "cell_type": "code",
   "source": "df.dtypes",
   "id": "e7812c85f7cc6e1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      datetime64[ns, UTC]\n",
       "fare_amount                      float64\n",
       "fare_class                         int64\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude                float64\n",
       "dropoff_latitude                 float64\n",
       "passenger_count                    int64\n",
       "dist_km                          float64\n",
       "EDTdate              datetime64[ns, UTC]\n",
       "Hour                               int32\n",
       "AMorPM                            object\n",
       "Weekday                           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert pandas dtypes",
   "id": "8844e70e7390d8ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:36:25.473843Z",
     "start_time": "2024-08-05T17:36:25.435617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')\n",
    "\n",
    "df.dtypes"
   ],
   "id": "dc40b90f191acef7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime      datetime64[ns, UTC]\n",
       "fare_amount                      float64\n",
       "fare_class                         int64\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude                float64\n",
       "dropoff_latitude                 float64\n",
       "passenger_count                    int64\n",
       "dist_km                          float64\n",
       "EDTdate              datetime64[ns, UTC]\n",
       "Hour                            category\n",
       "AMorPM                          category\n",
       "Weekday                         category\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:37:30.946989Z",
     "start_time": "2024-08-05T17:37:30.935476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# list the categories inside a pandas categorical field\n",
    "df['AMorPM'].cat.categories"
   ],
   "id": "28425fdaafa0e52d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:37:41.163669Z",
     "start_time": "2024-08-05T17:37:41.145396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# return a numpy array with the codes that corresponds to each category in the pd field\n",
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "print(hr, ampm, wkdy)"
   ],
   "id": "196ae2da063ff906",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 11  7 ... 14  4 12] [0 0 0 ... 1 0 1] [1 2 2 ... 3 5 2]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:37:57.133768Z",
     "start_time": "2024-08-05T17:37:57.126239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# stack together in a single array matrix\n",
    "cats = np.stack([hr, ampm, wkdy], axis=1)\n",
    "cats"
   ],
   "id": "deb2cf2917c95a2e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       ...,\n",
       "       [14,  1,  3],\n",
       "       [ 4,  0,  5],\n",
       "       [12,  1,  2]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:38:15.989733Z",
     "start_time": "2024-08-05T17:38:15.969999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create categorical codes matrix with list comprehension\n",
    "cats_l = np.stack([df[col].cat.codes.values for col in cat_cols], axis=1)\n",
    "cats"
   ],
   "id": "3461510923dc161f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       ...,\n",
       "       [14,  1,  3],\n",
       "       [ 4,  0,  5],\n",
       "       [12,  1,  2]], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:40:27.514735Z",
     "start_time": "2024-08-05T17:40:27.496677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create continuous matrix with list comprehension\n",
    "conts_l = np.stack([df[col].values for col in cont_cols], axis=1)"
   ],
   "id": "9ac4ca4297db4a07",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### PyTorch features and target tensors",
   "id": "e91949528761e251"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:41:27.196456Z",
     "start_time": "2024-08-05T17:41:27.146882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create categorical tensor\n",
    "cats = torch.tensor(cats_l, dtype=torch.int32)\n",
    "\n",
    "# create continuous tensor\n",
    "conts = torch.tensor(conts_l, dtype=torch.float32)\n",
    "\n",
    "# create label (y) tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float32)"
   ],
   "id": "57b236f89632bba3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:42:47.559723Z",
     "start_time": "2024-08-05T17:42:47.551081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# categorical sizes list\n",
    "cat_sizes = [len(df[col].cat.categories) for col in cat_cols]\n",
    "cat_sizes"
   ],
   "id": "6c7d37a9f6e6fcdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 2, 7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:43:05.732165Z",
     "start_time": "2024-08-05T17:43:05.714856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embedding sizes list (divide the number of unique entries in each column by two, if the result is grather than 50 select 50)\n",
    "emb_sizes = [(size, min(50,(size+1)//2)) for size in cat_sizes]\n",
    "emb_sizes"
   ],
   "id": "d2fdff3e748663b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Illustration of how will be trated the embedings inside the \"Tabular model\". The name \"Tabular Model\" comes from the fastai library and documentation https://docs.fast.ai/tabular.model.html",
   "id": "729704c50015ec7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:45:52.986429Z",
     "start_time": "2024-08-05T17:45:52.959978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# take a sample of the categorigal tensor\n",
    "cat_sample = cats[:2]\n",
    "cat_sample"
   ],
   "id": "b1f9774497280ced",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:46:36.735341Z",
     "start_time": "2024-08-05T17:46:36.710762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# with the embedding sizes list create torch embedding layers and store them in a ModuleList\n",
    "# modulelist is an iterator\n",
    "def create_emb_layers(emb_sizes):\n",
    "    mod_list = []\n",
    "    for ni, nf in emb_sizes:\n",
    "      mod_list.append(nn.Embedding(ni, nf))\n",
    "\n",
    "    self_embeddings = nn.ModuleList(mod_list)\n",
    "    return self_embeddings\n",
    "\n",
    "self_embeddings = create_emb_layers(emb_sizes)\n",
    "self_embeddings"
   ],
   "id": "309e57a196e0f1c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:46:57.457620Z",
     "start_time": "2024-08-05T17:46:57.443194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# list comprehension version for create embedding layers\n",
    "self_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_sizes])\n",
    "self_embeddings"
   ],
   "id": "4d6cb761ec50f657",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:47:19.924029Z",
     "start_time": "2024-08-05T17:47:19.903239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# recreation of the forward method\n",
    "embeddings_sample = []\n",
    "for i,e in enumerate(self_embeddings):\n",
    "    embeddings_sample.append(e(cat_sample[:,i]))\n",
    "embeddings_sample"
   ],
   "id": "621953e2302e0b14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.1937,  0.5139,  0.2956,  1.1011, -0.6396,  1.6985, -1.2358, -2.6161,\n",
       "          -0.2337,  0.3107,  0.8509,  0.2859],\n",
       "         [-0.1178, -0.7355,  0.6945,  0.5319,  0.3181,  0.2426,  1.7855, -0.5563,\n",
       "          -0.4952, -0.3381, -1.3796,  0.6923]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.4390],\n",
       "         [-0.4390]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-1.1825,  0.6685, -1.7540, -1.5680],\n",
       "         [-1.3548, -0.8874, -0.7264, -0.1126]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:49:58.304361Z",
     "start_time": "2024-08-05T17:49:58.284008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_sample = []\n",
    "for i,e in enumerate(self_embeddings):\n",
    "    emb_sample.append(cat_sample[:,i])\n",
    "emb_sample"
   ],
   "id": "5d56fbc46c780372",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 4, 11], dtype=torch.int32),\n",
       " tensor([0, 0], dtype=torch.int32),\n",
       " tensor([1, 2], dtype=torch.int32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T17:50:16.007471Z",
     "start_time": "2024-08-05T17:50:15.997249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# concatenate the embedded tensors by row\n",
    "z = torch.cat(embeddings_sample, 1)\n",
    "z"
   ],
   "id": "331e63c42efa04ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1937,  0.5139,  0.2956,  1.1011, -0.6396,  1.6985, -1.2358, -2.6161,\n",
       "         -0.2337,  0.3107,  0.8509,  0.2859, -0.4390, -1.1825,  0.6685, -1.7540,\n",
       "         -1.5680],\n",
       "        [-0.1178, -0.7355,  0.6945,  0.5319,  0.3181,  0.2426,  1.7855, -0.5563,\n",
       "         -0.4952, -0.3381, -1.3796,  0.6923, -0.4390, -1.3548, -0.8874, -0.7264,\n",
       "         -0.1126]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tabular model definition",
   "id": "649be95c794d67bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T18:58:39.731660Z",
     "start_time": "2024-08-05T18:58:39.681758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_sizes_s, n_cont, out_sizes, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_sizes_s])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.batch_norm_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layer_list = []\n",
    "        n_emb = sum([nf for ni, nf in emb_sizes_s])\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layer_list.append(nn.Linear(n_in, i))\n",
    "            layer_list.append(nn.ReLU(inplace=True))\n",
    "            layer_list.append(nn.BatchNorm1d(i))\n",
    "            layer_list.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "            \n",
    "        layer_list.append(nn.Linear(layers[-1], out_sizes))\n",
    "        \"\"\"In Python, the asterisk (*) operator is used for unpacking a list or a tuple. When you use it in the instruction self.layers = nn.Sequential(*layer_list), it effectively unpacks the elements of layer_list and passes them as individual arguments to the nn.Sequential constructor\"\"\"\n",
    "        self.layers = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:, i]))\n",
    "        \n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.batch_norm_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ],
   "id": "55c9c6cb9878f41",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training instances and datasets",
   "id": "958619d820b8a721"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T19:06:44.046256Z",
     "start_time": "2024-08-05T19:06:44.033736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model and early stop instances\n",
    "model = TabularModel(emb_sizes, conts.shape[1], 1, [200, 100], p=0.4).to(device)\n",
    "early_stop = EarlyStopping(patience=40)"
   ],
   "id": "a68fe92a4aeb33eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# combining categorical and continuous tensors for shuffling\n",
    "combined = torch.cat([cats, conts, y], dim=1)\n",
    "\n",
    "# torch to numpy array\n",
    "combined = combined.numpy()\n",
    "\n",
    "# splitting the combined data into train and test sets\n",
    "train_data, test_data = tra"
   ],
   "id": "c4ff1dcded31621e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
