{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dropout regularization \n",
    "When building effective deep learning models, we frequently encounter the challenge of overfitting, where a model performs exceptionally well on training data but fails to generalize well to unseen data. Regularization techniques are thus critical to ensure our model does not suffer from this common pitfall, striking a balance between bias (underfitting) and variance (overfitting). Regularization methods work by adding a penalty on the complexity of the model, effectively preventing the model fom learning too much noise from the training data and thus enhancing its ability to generalize.\n",
    "\n",
    "One such powerful regularization techniques is 'Dropout', a concept that metaphorically 'drops out' or temporarily 'turns off' a fraction of neurons in the model during training, thereby reducing the interdependencies of neurons. The randomness introduced by dropping out neurons compels the network to learn more robust features, leading to a more generalized and less overfit model.\n",
    "\n",
    "Dropout operates differently from most other regularization techniques. Instead of adding a penalty to the loss function, it randomly disables a fraction of neurons (defined by a probability parameter, typically ranging from 0.2 to 0.5), effectively creating a different architecture of the network for each training instance. This can be seen as training an ensemble of networks, which results in a more robust and generalizable final model.\n",
    "\n",
    "In this section , we will delve into the nuances of dropout, explore its theoretical underpinnings, and illustrate how to apply it using valious deep learning frameworks. Understanding and correctly implementing dropout is a valuable tool in the deep learning practitioner's toolkit, aiding the creation of robust and generalized models.\n",
    "\n",
    "As we go through the chapter, you will understand how dropout fits perfectly into the grand schema of regularization methods, learn about its benefits and limitations, and grasp how to effectively use dropout in your deep learning models.\n",
    "\n",
    "Dropout is a regularization technique that was introduced by Geoffrey Hinton, a pioneer in the field of deep learning, and his students Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov in a paper titled \"Dropout: A Simple Way to Prevent Neural Networks from Overfitting,\" which was published in 2014.\n",
    "\n",
    "The development of dropout came from the recognition of the challenges with overfitting in large neural networks. Large neural networks with millions of parameters are prone to overfitting because of their capacity to memorize training data. This is specially true when the amount of training data available is small relative to the complexity of the network.\n",
    "\n",
    "Goeofrrey Hinton, who is often referred as the \"godfather of deep learning\", has made several seminal contributions to the field of artificial intelligence, with dropout being just one of them. He and his team were looking for simple and effective ways to make neural networks more robust and to improve their generalization capabilities. Inspired by biological systems, they proposed the idea of dropout, which involves randomly \"dropping out\" or deactivating a subset of neurons during the training process to prevent them from co-adapting too much to the data.\n",
    "\n",
    "This simple yet effective technique has since been widely adopted in the deep learning community and has formed the basis of numerous subsequent research and developments. Dropout has proven to be a powerful tool in the training of neural networks, helping to mitigate overfitting and improve model generalization, particularly in scenarios with limited training data.\n",
    "\n",
    "Using the later example:"
   ],
   "id": "ae70297ebfba858f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T21:17:25.358192Z",
     "start_time": "2024-08-02T21:17:22.783688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "46fea9f7a5c0795e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T21:17:47.670045Z",
     "start_time": "2024-08-02T21:17:47.648561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selecting device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# early stopping definition\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "        \n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "        elif self.best_loss - val_loss >= self.min_delta:\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement found in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs\"\n",
    "                if self.restore_best_weights:\n",
    "                    model.load_state_dict(self.best_model)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "print(device)"
   ],
   "id": "fa10128d7a3326c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T21:18:37.222775Z",
     "start_time": "2024-08-02T21:18:37.205882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the data adn fill NA values with the median for all fields\n",
    "def fill_na_with_median(df):\n",
    "    \"\"\"\n",
    "    Replace all na values in numeric fields with median\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['float32', 'int32', 'int64', 'float64', 'long']:\n",
    "            median = df[col].median()\n",
    "            df[col] = df[col].fillna(median)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_dataset(route, fill_na=False):\n",
    "    df = pd.read_csv(route, na_values=[\"NA\", \"?\"])\n",
    "    if fill_na:\n",
    "      df = fill_na_with_median(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_dataset(\"data/jh-simple-dataset.csv\", fill_na=True)\n",
    "df.info()"
   ],
   "id": "607c6ff35d302f2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              2000 non-null   int64  \n",
      " 1   job             2000 non-null   object \n",
      " 2   area            2000 non-null   object \n",
      " 3   income          2000 non-null   float64\n",
      " 4   aspect          2000 non-null   float64\n",
      " 5   subscriptions   2000 non-null   int64  \n",
      " 6   dist_healthy    2000 non-null   float64\n",
      " 7   save_rate       2000 non-null   int64  \n",
      " 8   dist_unhealthy  2000 non-null   float64\n",
      " 9   age             2000 non-null   int64  \n",
      " 10  pop_dense       2000 non-null   float64\n",
      " 11  retail_dense    2000 non-null   float64\n",
      " 12  crime           2000 non-null   float64\n",
      " 13  product         2000 non-null   object \n",
      "dtypes: float64(7), int64(4), object(3)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T21:19:09.181602Z",
     "start_time": "2024-08-02T21:19:09.171420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate dummies\n",
    "def generate_dummies(df, dummies_list, drop_original=True):\n",
    "    \"\"\"Generate dummies for certain categorical columns\"\"\"\n",
    "    for col in dummies_list:\n",
    "        if df[col].dtype in ['object', 'categories']:\n",
    "            df = pd.concat([df, pd.get_dummies(df[col], prefix=col, dtype=int)], axis=1)\n",
    "            if drop_original:\n",
    "                df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_dummies(df, [\"job\", \"area\", \"product\"])\n",
    "df.info()"
   ],
   "id": "df16bb4399afddb3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 55 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              2000 non-null   int64  \n",
      " 1   income          2000 non-null   float64\n",
      " 2   aspect          2000 non-null   float64\n",
      " 3   subscriptions   2000 non-null   int64  \n",
      " 4   dist_healthy    2000 non-null   float64\n",
      " 5   save_rate       2000 non-null   int64  \n",
      " 6   dist_unhealthy  2000 non-null   float64\n",
      " 7   age             2000 non-null   int64  \n",
      " 8   pop_dense       2000 non-null   float64\n",
      " 9   retail_dense    2000 non-null   float64\n",
      " 10  crime           2000 non-null   float64\n",
      " 11  job_11          2000 non-null   int32  \n",
      " 12  job_al          2000 non-null   int32  \n",
      " 13  job_am          2000 non-null   int32  \n",
      " 14  job_ax          2000 non-null   int32  \n",
      " 15  job_bf          2000 non-null   int32  \n",
      " 16  job_by          2000 non-null   int32  \n",
      " 17  job_cv          2000 non-null   int32  \n",
      " 18  job_de          2000 non-null   int32  \n",
      " 19  job_dz          2000 non-null   int32  \n",
      " 20  job_e2          2000 non-null   int32  \n",
      " 21  job_f8          2000 non-null   int32  \n",
      " 22  job_gj          2000 non-null   int32  \n",
      " 23  job_gv          2000 non-null   int32  \n",
      " 24  job_kd          2000 non-null   int32  \n",
      " 25  job_ke          2000 non-null   int32  \n",
      " 26  job_kl          2000 non-null   int32  \n",
      " 27  job_kp          2000 non-null   int32  \n",
      " 28  job_ks          2000 non-null   int32  \n",
      " 29  job_kw          2000 non-null   int32  \n",
      " 30  job_mm          2000 non-null   int32  \n",
      " 31  job_nb          2000 non-null   int32  \n",
      " 32  job_nn          2000 non-null   int32  \n",
      " 33  job_ob          2000 non-null   int32  \n",
      " 34  job_pe          2000 non-null   int32  \n",
      " 35  job_po          2000 non-null   int32  \n",
      " 36  job_pq          2000 non-null   int32  \n",
      " 37  job_pz          2000 non-null   int32  \n",
      " 38  job_qp          2000 non-null   int32  \n",
      " 39  job_qw          2000 non-null   int32  \n",
      " 40  job_rn          2000 non-null   int32  \n",
      " 41  job_sa          2000 non-null   int32  \n",
      " 42  job_vv          2000 non-null   int32  \n",
      " 43  job_zz          2000 non-null   int32  \n",
      " 44  area_a          2000 non-null   int32  \n",
      " 45  area_b          2000 non-null   int32  \n",
      " 46  area_c          2000 non-null   int32  \n",
      " 47  area_d          2000 non-null   int32  \n",
      " 48  product_a       2000 non-null   int32  \n",
      " 49  product_b       2000 non-null   int32  \n",
      " 50  product_c       2000 non-null   int32  \n",
      " 51  product_d       2000 non-null   int32  \n",
      " 52  product_e       2000 non-null   int32  \n",
      " 53  product_f       2000 non-null   int32  \n",
      " 54  product_g       2000 non-null   int32  \n",
      "dtypes: float64(7), int32(44), int64(4)\n",
      "memory usage: 515.8 KB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-02T21:19:33.328257Z",
     "start_time": "2024-08-02T21:19:33.322743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# standardize ranges\n",
    "num_fields = ['income', 'aspect', 'save_rate', 'subscriptions']\n",
    "for field in num_fields:\n",
    "    df[field] = zscore(df[field])"
   ],
   "id": "cca835cbd4bd0c13",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "To add dropout to the existing code, we will use the `nn.Dropout` PyTorch module. It randomly zeroes some of the elements of the input tensor with probability `p` during training, which can help prevent overfitting. The modified code is shown below with the dropout layers added.\n",
    "```\n",
    "# Create the model with dropout\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 20),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "```"
   ],
   "id": "8c05d3df5822d975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a585fd694cdb1330"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
