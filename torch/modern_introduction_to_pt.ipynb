{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pytorch as high performance linear algebra library\n",
    "PyTorch is a library for linear algebra, other components of PyTorch are a higher-level abstraction for neural networks that you build upon the lower level linear algebra.\n",
    "\n",
    "PyTorch can compute on a GPU, CPU, or other advanced compute device. If you are using a Mac, PyTorch is now adding additional support for Apple silicone (M1, M2, M3, etc). For apple support we will use Metal Performance Shaders (MPS). For this course, we assume you will utilize a GPU (cuda), CPU, or MPS. The following code detects the available device and defines the device variable that the following code will use for computation. For parts of this course that I know do not work for MPS, we will fall back to CPU. CUDA is an NVIDIA standard for accessing GPU capabilities."
   ],
   "id": "69e20454db7eb4ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:53:49.520904Z",
     "start_time": "2024-07-23T13:53:47.181998Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "f3b510382cb1e8c1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:53:50.993367Z",
     "start_time": "2024-07-23T13:53:50.950882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# selecting a device \n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "id": "82b02408359c85df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:54:29.535136Z",
     "start_time": "2024-07-23T13:54:29.161632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a Constant op that produces a 1x2 matrix.  The op is  added as a node to the default graph.\n",
    "\n",
    "# The value returned by the constructor represents the output of the Constant op.\n",
    "matrix1 = torch.tensor([[3.0, 3.0]], device=device)\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = torch.tensor([[2.0], [2.0]], device=device)\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix multiplication\n",
    "product = torch.mm(matrix1, matrix2)\n",
    "\n",
    "print(product)\n",
    "print(float(product))"
   ],
   "id": "ab7e099859d94e7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.]], device='cuda:0')\n",
      "12.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This example multiplied two PyTorch tensors. You can see that we created each tensor on the appropriate device, either the GPU or CPU. Next, we will see how to subtract a constant from a variable.",
   "id": "5db46cf9812cb219"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T13:59:14.059612Z",
     "start_time": "2024-07-23T13:59:14.042710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([[1.0], [2.0]], device=device)\n",
    "a = torch.tensor([[3.0], [3.0]], device=device)\n",
    "\n",
    "# subtracting 'a' from 'x' \n",
    "sub = torch.subtract(x, a)\n",
    "print(sub)"
   ],
   "id": "f59df9ea3250aa36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.],\n",
      "        [-1.]], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Of course, variables are only helpful if we can change their values. The program can accomplish this change in value by calling the assign function. To use Numpy, we must first bring the tensor back to the CPU with the cpu() command. Next, we call numpy() to access the tensor as a Numpy array. If we were already on the CPU, this function has no effect and returns the already CPU-resident tensor.",
   "id": "b9a4ad249339f72b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:12:07.224762Z",
     "start_time": "2024-07-23T14:12:07.216132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x[0] = 4.0\n",
    "x[1] = 6.0"
   ],
   "id": "36b3a73b9e160ef4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The program can now perform the substraction with this new value",
   "id": "f6fd4d068dacfd33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T14:12:10.872550Z",
     "start_time": "2024-07-23T14:12:10.866774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sub = torch.subtract(x, a)\n",
    "print(sub)\n",
    "print(sub.cpu().numpy())"
   ],
   "id": "51654b0449587a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [3.]], device='cuda:0')\n",
      "[[1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
